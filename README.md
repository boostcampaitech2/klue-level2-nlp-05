# KLUE LEVEL2 NLP Team 5 - ã…‡ã„±ã„¹ã…‡

## Updates

* (17:53, Oct 5) ìë™ìœ¼ë¡œ validation datasetì„ splití•©ë‹ˆë‹¤. `--val_ratio 0.2`ê°€ default ê°’ì´ë©°, `--val_ratio 0.0`ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ evaluationì„ ì§„í–‰í•˜ê²Œ ë©ë‹ˆë‹¤.

  * ë”°ë¼ì„œ ì‹¤í—˜ ì¤‘ì—ëŠ” ì¶”ê°€ì ì¸ ì„¤ì •ì„ í•˜ì‹¤ í•„ìš”ê°€ ì—†ì§€ë§Œ, ai stagesì— ì œì¶œì‹œì—ëŠ” `--val_ratio 0.0 --eval_every 10000` ì •ë„ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”! (eval every ì˜µì…˜ì„ ì¤˜ì•¼ í›ˆë ¨ ì‹œê°„ì´ ë‹¨ì¶•ë©ë‹ˆë‹¤.)

* (18:23, Oct 5) `--save_every 2000 --log_every 2000 --eval_every 2000` ì •ë„ë¡œ ì„¤ì •í•´ì£¼ì…”ë„ ì¶©ë¶„íˆ evaluation ê°€ëŠ¥í•˜ë‹ˆ í›ˆë ¨ ì†ë„ ë¹ ë¥´ê²Œ í•˜ê¸° ìœ„í•´ì„œëŠ” ì´ ë°©ë²• ì‹œë„í•´ë³´ì„¸ìš”~

* (0:55, Oct 6) train, valid set ë‚˜ëˆŒ ë•Œ `--verbose y`ë¡œ ì„¤ì •í•˜ë©´, ê° setì— í¬í•¨ëœ ë¼ë²¨ë³„ ë°ì´í„° ìˆ˜ë¥¼ ì¶œë ¥í•´ì¤ë‹ˆë‹¤. ì°¸ê³ í•˜ì„¸ìš”~

# Instruction

## Data Augmentation

ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ì „ì—, ë°ì´í„° ìˆ˜ ì¦ê°€ë¥¼ ìœ„í•´ ì—¬ëŸ¬ Data Augmentationê¸°ë²•ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.<br>
Augmentationì„ ì ìš©í•œ ë°ì´í„°ì…‹ë“¤ì€ "/opt/ml/dataset" í•˜ìœ„ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

### AEDA

```bash
python aeda_augmentation.py
```

### Swap

```bash
python swap_augmentation.py
```

### Load augmented data

ì•„ë˜ì˜ argumentë¥¼ ì¶”ê°€í•˜ë©´ ì‚¬ì „ì— augmentationì´ ì´ë£¨ì–´ì§„ dataë¥¼ ë°›ìŠµë‹ˆë‹¤. `--data_dir` ë‚´ì˜ í•˜ë¶€ ë””ë ‰í† ë¦¬ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.

```bash
--additional folder1/train.csv folder2/train.csv
```

ì˜ˆë¥¼ ë“¤ì–´, `--data_dir /opt/ml/dataset`ìœ¼ë¡œ ì§€ì •ë˜ì–´ ìˆë‹¤ë©´, `/opt/ml/dataset/folder1/train.csv`, `/opt/ml/dataset/folder2/train.csv`ë¥¼ ë¶ˆëŸ¬ì˜¤ê²Œ ë©ë‹ˆë‹¤.

## How to train

ëŒ€íšŒì—ì„œ ì£¼ì–´ì§„ ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ì–‘í•œ ì˜µì…˜ì„ ì´ìš©í•´ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ì½”ë“œë¡œ ëŒ€íšŒ ì´ˆê¸°ì— ì£¼ì–´ì§„ baseline setting ê·¸ëŒ€ë¡œ ëŒë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

### Baseline Model (klue/bert-base)

```bash
python train.py --verbose y --name exp_baseline --model klue/bert-base --dataset BaselineDataset --data_dir /opt/ml/dataset --preprocessor BaselinePreprocessor --epochs 1 --lr 1e-3
```

### Electra

```bash
python train.py --verbose y --name exp_electra --model kykim/electra-kor-base --dataset BaselineDataset --data_dir /opt/ml/dataset --preprocessor BaselinePreprocessor --epochs 1 --lr 1e-3
```

### Roberta

```bash
python train.py --verbose y --name exp_roberta --model klue/roberta-large --dataset BaselineDataset --data_dir /opt/ml/dataset --preprocessor BaselinePreprocessor --epochs 1 --lr 1e-3
```

```bash
python train.py --verbose y --name exp_roberta --model klue/roberta-base --dataset BaselineDataset --data_dir /opt/ml/dataset --preprocessor BaselinePreprocessor --epochs 1 --lr 1e-3
```

```bash
python train.py --verbose y --name exp_roberta --model klue/roberta-small --dataset BaselineDataset --data_dir /opt/ml/dataset --preprocessor BaselinePreprocessor --epochs 1 --lr 1e-3
```

### T5

```bash
python train.py --verbose y --name exp_t5 --model KE-T5-large --dataset T5Dataset --data_dir /opt/ml/dataset --preprocessor T5BasicPreprocessor --epochs 1 --lr 1e-3
```

```bash
python train.py --verbose y --name exp_t5 --model KE-T5-base --dataset T5Dataset --data_dir /opt/ml/dataset --preprocessor T5BasicPreprocessor --epochs 1 --lr 1e-3
```

```bash
python train.py --verbose y --name exp_t5 --model KE-T5-small --dataset T5Dataset --data_dir /opt/ml/dataset --preprocessor T5BasicPreprocessor --epochs 1 --lr 1e-3
```

### Help

ìì„¸í•œ commandline argumentsì— ëŒ€í•œ ë‚´ìš©ì€ ì•„ë˜ì˜ ëª…ë ¹ì–´ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```bash
python train.py --help
```

### Final Submission

ëŒ€íšŒì— ìµœì¢…ìœ¼ë¡œ ì œì¶œí•œ settingì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```bash
python train.py
```

## How to infer

### ğŸš§ğŸš§ğŸš§ Under Construction ğŸš§ğŸš§ğŸš§

## Features

ê°€ì¥ í° íŠ¹ì§•ë“¤ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

* huggingface ë‚´ ëª¨ë¸ë¿ë§Œ ì•„ë‹ˆë¼ model í´ë” ë‚´ì— ì €ì¥ëœ custom modelì„ commandline argumentë¡œ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ë”°ë¼ì„œ ë‹¤ì–‘í•œ pretrained ëª¨ë¸ì„ ëª…ë ¹ë§Œì„ í†µí•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í¸ì˜ì„±ì„ ë†’ì´ë©´ì„œë„, ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ììœ ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤. (ë‹¤ë§Œ, ëª¨ë¸ì— ì í•©í•œ inputì— ë§ê²Œ `Preprocessor`ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.)

* ë‹¤ì–‘í•œ ì „ì²˜ë¦¬, ëª¨ë¸ì˜ ì‹¤í—˜ì„ ì½”ë“œì˜ ìµœì†Œí•œì˜ ë³€í˜•ë§Œìœ¼ë¡œ ê°€ëŠ¥í•˜ë„ë¡ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.

* wandbê°€ ì—°ë™ë˜ì–´ í›ˆë ¨ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ëª¨ë¸ë“¤ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ hyperparameter searchë¥¼ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

* `Preprocessor`ë¥¼ ìƒì†ë°›ëŠ” subclass `preprocessor` objectë¥¼ ë§Œë“¤ì–´ì„œ ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ë¥¼ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, êµ¬í˜„ëœ ì—¬ëŸ¬ ê°œì˜ ì „ì²˜ë¦¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* `Augmentation`ì„ ìƒì†ë°›ëŠ” subclass `augmentation` objectë¥¼ ë§Œë“¤ì–´ì„œ ë‹¤ì–‘í•œ augmentationì„ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ êµ¬í˜„ëœ ì—¬ëŸ¬ ê°œì˜ ë°ì´í„° ì¦ê°• ê¸°ë²•ì„ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## TODO List

- [X] ë‹¤ì–‘í•œ ëª¨ë¸(T5 ë“±)ì˜ inputì— ì í•©í•œ `Preprocessor` í´ë˜ìŠ¤ ê°œë°œ
- [X] EDA ë…¼ë¬¸ì— ë‚˜ì˜¨ Augmentation êµ¬í˜„
- [ ] Word2Vec í˜¹ì€ FastText ê¸°ë°˜ì˜ ìœ ì˜ì–´ ì‚¬ì „ êµ¬ì¶• ë° Augmentation êµ¬í˜„
- [X] train-valid split êµ¬í˜„ (stratified)
- [ ] huggingface `Trainer`ì— ë‹¤ì–‘í•œ optimizer ì˜µì…˜ ì¶”ê°€ (ì˜ˆë¥¼ ë“¤ì–´, `--optim` ì˜µì…˜ì€ ì •ìƒìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)

# Structure

## File Structure

ã…‡ã„±ã„¹ã…‡íŒ€ ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

<details>
  <summary>Click to expand!</summary>

  ```
.
|-- README.md
|-- dataset
|   |-- augmentation
|   |   `-- augmentations.py
|   |-- dataset.py
|   |-- preprocessor
|   |   |-- preprocessors.py
|   |   `-- regex.py
|   `-- transform.py
|-- exp.ipynb
|-- infer.py
|-- ipynb
|-- model
|   `-- models.py
|-- requirements.txt
`-- train.py
  ```
</details>

## Class ì„¤ëª…

### `dataset.preprocessor.preprocessors`:

#### `Preprocessor` class

* ê¸°ë³¸ì ì¸ êµ¬í˜„ì€ `pandas.DataFrame`ì„ ë°›ì•„ì„œ ì›í•˜ëŠ” ëŒ€ë¡œ ê°€ê³µí•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

* í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ í˜¸ì¶œ(`preprocessor(data: pd.DataFrame)`)í•˜ë©´ ë³€í˜•ëœ í˜•íƒœì˜ `pandas.DataFrame`ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

* í˜„ì¬ ì¶”ìƒ í´ë˜ìŠ¤ `Preprocessor`ë¥¼ ìƒì†ë°›ëŠ” í´ë˜ìŠ¤ëŠ” 1ê°œ `BaselinePreprocessor`ê°€ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œê°€ í•˜ëŠ” ì—­í• ê³¼ ê±°ì˜ ìœ ì‚¬í•©ë‹ˆë‹¤.

#### `BaselinePreprocessor` class

* `BaselinePreprocessor`ê°€ ìˆ˜í–‰í•˜ëŠ” ì—­í• ì€ ë„˜ê²¨ë°›ì€ dataì˜ ë¼ë²¨ì„ `subject_entity`, `object_entity`, `concat_entity`, `label`ë¡œ ë‚˜ëˆ„ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

* ì´í›„, `concat_entity`ëŠ” `BaselineDataset`ì—ì„œ `sentence`ì™€ í•¨ê»˜ ëª¨ë¸ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì£¼ì–´ì§€ê²Œ ë˜ë©°, ë‘˜ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ `token_type_ids`ê°€ ì¶”ê°€ëœ ì±„ë¡œ ëª¨ë¸ì— ì£¼ì–´ì§‘ë‹ˆë‹¤.

----------

### `dataset.augmentation.augmentations`:

* ê¸°ë³¸ì ì¸ êµ¬í˜„ì€ ê°œë³„ sentence `str`ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê°€ê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

* sentenceê°€ `dataset.tokenizer`ì— ì˜í•´ í† í°í™”ë˜ê¸° ì „ì— ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. í•´ë‹¹ ì´ìœ ëŠ” í•œêµ­ì–´ íŠ¹ì„±ìƒ word ë‹¨ìœ„ê°€ ì•„ë‹Œ subword ê¸°ë°˜ì˜ í† í°í™”ë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ”ë°, ì´ ê²½ìš° ì²˜ë¦¬ê°€ ìƒë‹¹íˆ ê¹Œë‹¤ë¡­ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

* í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ í˜¸ì¶œ(`augmentation(input_text: str)`)í•˜ë©´ ê°€ê³µëœ í˜•íƒœì˜ `str`ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

* í˜„ì¬ ì´ 3ê°œì˜ ì¶”ìƒ í´ë˜ìŠ¤ `Augmentation`ì„ ìƒì†ë°›ì€ í´ë˜ìŠ¤ê°€ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

#### `SimpleRandomUNK` class

* `__init__(unk_token: str, unk_ratio: float = 0.15)`

* `unk_token`ì€ ì¼ë°˜ì ìœ¼ë¡œ tokenizerì—ì„œ ë°˜í™˜ë˜ëŠ” í† í°ì„ ì…ë ¥í•˜ê²Œ ë©ë‹ˆë‹¤.

* `unk_ratio`ëŠ” `<unk>` í† í°ìœ¼ë¡œ ì²˜ë¦¬í•  ë‹¨ì–´ì˜ ë¹„ìœ¨ì„ ì •í•©ë‹ˆë‹¤. ì „ì²´ ë‹¨ì–´ ìˆ˜ (ë„ì–´ì“°ê¸° ê¸°ì¤€) ì¤‘ì—ì„œ í•´ë‹¹ ë¹„ìœ¨ë§Œí¼ (í™•ë¥ ì ìœ¼ë¡œ) `<unk>` í† í°ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.

#### `UNKWithInputMask` class

* ì…ë ¥ê°’ìœ¼ë¡œ `input_mask`ë¥¼ ë°›ì•„, `input_mask`ì˜ `0`ìœ¼ë¡œ ì£¼ì–´ì§„ ê³³ì˜ ë‹¨ì–´ì— ëŒ€í•´ì„œë§Œ **ëª¨ë‘** `<unk>` í† í°ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.

#### `RandomUNKWithInputMask` class

* ìœ„ì˜ `SimpleRandomUnk`ì™€ `UnkWithInputMask` í´ë˜ìŠ¤ì˜ ê¸°ëŠ¥ì„ ëª¨ë‘ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì…ë ¥ê°’ìœ¼ë¡œëŠ” `input_mask`ë¥¼ ë°›ìŠµë‹ˆë‹¤.

* `input_mask`ì˜ `0`ìœ¼ë¡œ ì£¼ì–´ì§„ ê³³ì˜ ë‹¨ì–´ì— ëŒ€í•´ì„œë§Œ **í™•ë¥ ì ìœ¼ë¡œ** `<unk>` í† í°ìœ¼ë¡œ ëŒ€ì²´í•˜ë©°, `1`ë¡œ ì£¼ì–´ì§„ ê³³ì€ ì ˆëŒ€ë¡œ ëŒ€ì²´ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 

* ì°©ì˜¤ ë° ì‹¤ìˆ˜ë¡œ ì¸í•´ `input_text`ì˜ ë‹¨ì–´ìˆ˜ì™€ `input_mask`ì˜ ê°œìˆ˜ê°€ ë‹¤ë¥´ë”ë¼ë„, ì´ë¥¼ ì—ëŸ¬ ì—†ì´ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œê°€ ë“¤ì–´ ìˆì–´ ë…¸ì´ì¦ˆì— ëŒ€ì‘í•©ë‹ˆë‹¤. 

* `compensate = True`ì¼ ê²½ìš°, `input_mask`ê°€ ì”Œì›Œì§„ ë¹„ìœ¨ë§Œí¼ `unk_ratio`ë¥¼ ë³´ì •í•˜ì—¬ í™•ë¥ ì ìœ¼ë¡œ ë§ˆìŠ¤í¬ë¥¼ ì”Œì›ë‹ˆë‹¤.

* `compensate = True`ê°€ ê¸°ë³¸ê°’ì´ë©°, `conpensate = False`ì¼ ê²½ìš°ëŠ” `unk_ratio`ë¡œ ì´ˆê¸°í™”ëœ ê°’ê³¼ë³´ë‹¤ í›¨ì”¬ ì ì€ ë¹„ìœ¨ì˜ ë§ˆìŠ¤í¬ê°€ ì”Œì›Œì§ˆ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.

# Arguments

## Container Environments

```bash
--data_dir {data_directory}   # default: /opt/ml/dataset
--model_dir {model_directory} # default: ./saved
--log_dir {model_directory}   # default: ./logs
```

## Model Setting

```bash
--name {save_name}           # please set the model name
--model {model_type}         # model type (e.g., klue/bert-base)
--load_model {model_dir}     # if set, load a custom pretrained model
--num_labels {num_labels}    # num_labels (default: 30)
```

## Dataset and DataLoader

```bash
--dataset {dataset}            # dataset class name (default: BaselineDataset)
--additional {file1 file2 ...} # list of additional dataset file names (will be concated)
--batch_size {B}               # batch size (default: 1)
--val_ratio {val_ratio}        # stratified train-valid split ratio (default: 0.2)
                               # if val_ratio == 0, then evaluate with the whole training data
--val_batch_size {batch_size}  # default set to batch_size
```

## Preprocessor and Augmentation

```bash
--preprocessor {prp_type}    # default: BaselinePreprocessor
--augmentation {aug_type}    # default: None
```

## Training Setup

```bash
--epochs {N}         # number of epochs (default: 1)
--lr {LEARNING_RATE} # learning rate (default: 1e-5)
--max_seq_len {L}    # max sequence length (default: 256)
--max_pad_len {L}    # max padding length (default: 8)
```

## Trainer Setup

```bash
--log_every {N}     # log every N steps (default: 500)
--eval_every {N}    # evaluation interval for every N steps (default: 500)
--save_every {N}    # save model interval for every N steps (default: 500)
```

## Additional Setting

If saved model directory is given to `--load_model`, then it will load the pretrained weights.

```bash
--seed {seed_value}  # default: None
--verbose {y or n}   # y or n
```
